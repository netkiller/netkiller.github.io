<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>5. Hadoop - HDFS</title><link rel="stylesheet" type="text/css" href="..//docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets V1.76.1" /><meta name="keywords" content="&#10;bash,bunzip2,busybox,bzcat,bzcmp,bzdiff,bzegrep,bzexe,bzfgrep,bzgrep,bzip2,bzip2recover,bzless,bzmore,cat,chgrp,chmod,chown,chvt,cp,cpio,dash,date,dbus-cleanup-sockets,dbus-daemon,dbus-uuidgen,dd,df,dir,dmesg,dnsdomainname,domainname,dumpkeys,echo,ed,egrep,false,fgconsole,fgrep,fuser,fusermount,grep,gunzip,gzexe,gzip,hostname,ip,kbd_mode,kill,less,lessecho,lessfile,lesskey,lesspipe,ln,loadkeys,login,ls,lsmod,mkdir,mknod,mktemp,more,mount,mountpoint,mt,mt-gnu,mv,nano,nc,nc.openbsd,netcat,netstat,nisdomainname,ntfs-3g,ntfs-3g.probe,ntfs-3g.secaudit,ntfs-3g.usermap,open,openvt,pidof,ping,ping6,plymouth,ps,pwd,rbash,readlink,rm,rmdir,rnano,run-parts,sed,setfont,setupcon,sh,sh.distrib,sleep,static-sh,stty,su,sync,tailf,tar,tempfile,touch,true,ulockmgr_server,umount,uname,uncompress,unicode_start,vdir,which,ypdomainname,zcat,zcmp,zdiff,zegrep,zfgrep,zforce,zgrep,zless,zmore,znew,,/sbin/:,acpi_available,apm_available,apparmor_parser,badblocks,blkid,blockdev,bootlogd,cfdisk,crda,ctrlaltdel,debugfs,depmod,dhclient,dhclient3,dhclient-script,dmsetup,dosfsck,dosfslabel,dump,dumpe2fs,e2fsck,e2image,e2label,e2undo,ethtool,fdisk,findfs,fsck,fsck.cramfs,fsck.ext2,fsck.ext3,fsck.ext4,fsck.ext4dev,fsck.minix,fsck.msdos,fsck.nfs,fsck.vfat,fstab-decode,getty,halt,hdparm,hwclock,ifconfig,ifdown,ifquery,ifup,init,initctl,insmod,insserv,installkernel,ip,ip6tables,ip6tables-restore,ip6tables-save,ipmaddr,iptables,iptables-restore,iptables-save,iptunnel,isosize,iwconfig,iwevent,iwgetid,iwlist,iwpriv,iwspy,kbdrate,killall5,ldconfig,ldconfig.real,logsave,losetup,lsmod,MAKEDEV,mii-tool,mkdosfs,mke2fs,mkfs,mkfs.bfs,mkfs.cramfs,mkfs.ext2,mkfs.ext3,mkfs.ext4,mkfs.ext4dev,mkfs.minix,mkfs.msdos,mkfs.vfat,mkhomedir_helper,mkswap,modinfo,modprobe,mountall,mount.fuse,mount.nfs,mount.nfs4,mount.ntfs,mount.ntfs-3g,nameif,on_ac_power,pam_tally,parted,partprobe,pivot_root,plipconfig,plymouthd,pmap_dump,pmap_set,portmap,poweroff,rarp,raw,rdump,reboot,regdbdump,reload,resize2fs,restart,restore,rfkill,rmmod,route,rpc.statd,rrestore,rtacct,rtmon,runlevel,sfdisk,shadowconfig,showmount,shutdown,slattach,sm-notify,ss,start,startpar,start-stop-daemon,status,stop,sulogin,swapoff,swapon,switch_root,sysctl,tc,telinit,tune2fs,udevadm,udevd,umount.nfs,umount.nfs4,unix_chkpwd,unix_update,upstart-udev-bridge,ureadahead,wipefs,wpa_action,wpa_cli,wpa_supplicant&#10;&#9;&#9;&#9;, &#10;a2p,acyclic,addftinfo,addpart,afmtodit,animate,anytopnm,apg,apgbfm,apport-bug,apport-cli,apport-collect,apport-unpack,apropos,apt-cache,apt-cdrom,apt-config,apt-extracttemplates,apt-ftparchive,apt-get,aptitude,aptitude-create-state-bundle,aptitude-run-state-bundle,apt-key,apt-mark,apt-sortpkgs,arch,arping,asciitopgm,at,atktopbm,atq,atrm,awk,base64,basename,bashbug,batch,bc,bcomps,bconsole,bdftopcf,bdftops,bdftruncate,bioradtopgm,bmptopnm,bmptoppm,brushtopbm,bsd-mailx,bsd-write,byobu,byobu-config,byobu-export,byobu-janitor,byobu-launch,byobu-launcher,byobu-launcher-install,byobu-launcher-uninstall,byobu-reconnect-sockets,byobu-select-profile,byobu-select-session,byobu-status,byobu-status-detail,c2ph,cal,calendar,captoinfo,catchsegv,catman,cautious-launcher,ccomps,chage,chattr,chcon,check-bios-nx,check-language-support,chem,chfn,chkdupexe,chrt,chsh,circo,ckbcomp,ck-history,ck-launch-session,ck-list-sessions,cksum,clear,clear_console,cmp,cmuwmtopbm,codepage,col,colcrt,colrm,column,comm,compare,compose,composite,config_data,conjure,convert,corelist,cpan,cpan2dist,cpanp,cpanp-run-perl,cpp,cpp-4.4,createrepo,c_rehash,crontab,csplit,ctstat,curl,curlftpfs,cut,dbilogstrip,dbiprof,dbiproxy,dbmmanage,dbus-monitor,dbus-send,ddate,deallocvt,debconf,debconf-apt-progress,debconf-communicate,debconf-copydb,debconf-escape,debconf-set-selections,debconf-show,defoma,defoma-app,defoma-font,defoma-hints,defoma-id,defoma-psfont-installer,defoma-subst,defoma-user,delpart,dh_bash-completion,dh_installdefoma,dh_installxmlcatalogs,dh_pycentral,dh_pysupport,dialog,diff,diff3,diffimg,dig,dijkstra,dircolors,dirname,display,do-release-upgrade,dot,dot2gxl,dotlockfile,dotty,dpkg,dpkg-deb,dpkg-divert,dpkg-query,dpkg-split,dpkg-statoverride,dpkg-trigger,dprofpp,du,dumphint,dumpkeys,dvipdf,easy_install,easy_install-2.6,edit,editor,eject,enc2xs,encode_keychange,env,envsubst,eps2eps,epsffit,eqn,eqn2graph,ex,expand,expiry,expr,extractres,eyuvtoppm,factor,faillog,fallocate,fc-cache,fc-cat,fc-list,fc-match,fc-query,fc-scan,fdp,fiascotopnm,file,find,find2perl,findsmb,fitstopnm,fixdlsrps,fixfmps,fixmacps,fixproc,fixpsditps,fixpspps,fixscribeps,fixtpps,fixwfwps,fixwpps,fixwwps,flock,flow-capture,flow-cat,flow-dscan,flow-expire,flow-export,flow-fanout,flow-filter,flow-gen,flow-header,flow-import,flow-log2rrd,flow-mask,flow-merge,flow-nfilter,flow-print,flow-receive,flow-report,flow-rpt2rrd,flow-rptfmt,flow-send,flow-split,flow-stat,flow-tag,flow-xlate,fmt,fold,font2c,fontconfig-voodoo,fonttosfnt,fping,fping6,free,fribidi,from,fstopgm,ftp,funzip,g3topbm,gawk,gc,gdiffmk,gdk-pixbuf-query-loaders,gemtopbm,gemtopnm,gendiff,geqn,GET,getafm,getconf,getent,getkeycodes,getopt,gettext,gettext.sh,ghostscript,giftopnm,ginstall-info,gio-querymodules,git,git-receive-pack,git-shell,git-upload-archive,git-upload-pack,gmetric,gnokii,gnuplot,gnuplot-nox,gouldtoppm,gpasswd,gpg,gpgsplit,gpgv,gpg-zip,gpic,grap2graph,grn,grodvi,groff,groffer,grog,grolbp,grolj4,grops,grotty,groups,grub-bin2h,grub-editenv,grub-fstest,grub-mkelfimage,grub-mkfont,grub-mkimage,grub-mkisofs,grub-mkpasswd-pbkdf2,grub-mkrelpath,grub-mkrescue,grub-script-check,gs,gsbj,gsdj,gsdj500,gslj,gslp,gsnd,gstat,gtbl,gtk-query-immodules-2.0,gtk-update-icon-cache,gvcolor,gvimtutor,gvpack,gvpr,gxditview,gxl2dot,h2ph,h2xs,hd,head,HEAD,helpztags,hexdump,hipstopgm,host,hostid,hpftodit,htdbm,htdigest,htpasswd,i386,icontopbm,iconv,id,identify,igawk,ilbmtoppm,imgtoppm,import,includeres,indexer,indxbib,info,infobrowser,infocmp,infokey,infotocap,innochecksum,innotop,install,install-info,instmodsh,ionice,iostat,ipcmk,ipcrm,ipcs,ipmicmd,ipmilan,ipmish,ipmitool,ipmi_ui,iptables-xml,join,jpegtopnm,killall,kvm-ok,l4p-tmpl,landscape-sysinfo,last,lastb,lastlog,lcf,ldd,leaftoppm,lefty,less,lessecho,lessfile,lesskey,lesspipe,lexgrog,libnetcfg,line,link,linux32,linux64,linux-boot-prober,lispmtopgm,lkbib,lneato,lnstat,loadkeys,loadunimap,locale,localedef,locate,lockfile-check,lockfile-create,lockfile-remove,lockfile-touch,logger,logname,look,lookbib,lorder,lsattr,lsb_release,lscpu,lshw,lsof,lspci,lspgpot,lsusb,ltrace,lwp-download,lwp-dump,lwp-mirror,lwp-request,lwp-rget,lzcat,lzma,macptopbm,mail,Mail,mail-lock,mailq,mail-touchlock,mail-unlock,mailx,make,make-memtest86+-boot-floppy,make_method,man,mandb,manhole,manpath,mapscrn,mawk,mcookie,md5sum,md5sum.textutils,mdatopbm,memcached,mesg,mgrtopbm,mkfifo,mkfontdir,mkfontscale,mk_modmap,mktap,mlocate,mmroff,modifyrepo,mogrify,montage,motd+shell,mpstat,msql2mysql,mtr,mtvtoppm,munin-check,munin-cron,munindoc,mutt,mutt_dotlock,myisamchk,myisam_ftdump,myisamlog,myisampack,my_print_defaults,mysql,mysqlaccess,mysqladmin,mysqlanalyze,mysqlbinlog,mysqlbug,mysqlcheck,mysql_client_test,mysql_client_test_embedded,mysql_convert_table_format,mysqld_multi,mysqld_safe,mysqldump,mysqldumpslow,mysql_find_rows,mysql_fix_extensions,mysql_fix_privilege_tables,mysqlhotcopy,mysqlimport,mysql_install_db,mysqloptimize,mysqlrepair,mysqlreport,mysql_secure_installation,mysql_setpermission,mysqlshow,mysqlslap,mysqltest,mysqltest_embedded,mysql_tzinfo_to_sql,mysql_upgrade,mysql_waitpid,mysql_zap,mytop,namei,nano,nawk,ncal,ncat,ncftp,ncftp3,ncftpbatch,ncftpbookmarks,ncftpget,ncftpls,ncftpput,ncftpspooler,ncurses5-config,ncursesw5-config,ndiff,neato,neotoppm,neqn,net,netkit-ftp,net.samba3,net-snmp-config,netstat-nat,newaliases,newgrp,ngettext,nice,nl,nmap,nmblookup,nmblookup.samba3,nmon,nohup,nop,nroff,nslookup,nstat,nsupdate,od,oldfind,omshell,on_ac_power,openipmicmd,openipmish,openssl,openssl-vulnkey,os-prober,pager,palmtopnm,pamcut,pamdeinterlace,pamdice,pamfile,pamoil,pamstack,pamstretch,pamstretch-gen,paperconf,parsechangelog,partx,passwd,paste,patch,pathchk,pbmclean,pbmlife,pbmmake,pbmmask,pbmpage,pbmpscale,pbmreduce,pbmtext,pbmtextps,pbmto10x,pbmtoascii,pbmtoatk,pbmtobbnbg,pbmtocmuwm,pbmtoepsi,pbmtoepson,pbmtog3,pbmtogem,pbmtogo,pbmtoicon,pbmtolj,pbmtomacp,pbmtomda,pbmtomgr,pbmtonokia,pbmtopgm,pbmtopi3,pbmtoplot,pbmtoppa,pbmtopsg3,pbmtoptx,pbmtowbmp,pbmtox10bm,pbmtoxbm,pbmtoybm,pbmtozinc,pbmupc,pcimodules,pcretest,pcxtoppm,pdb,pdb2.6,pdb3,pdb3.1,pdf2dsc,pdf2ps,pdfopt,pdfroff,pear,peardev,pecl,peekfd,perl,perl5.10.1,perlbug,perldoc,perlivp,perlthanks,perror,pf2afm,pfbtopfa,pfbtops,pfc,pftp,pg,pgawk,pgmbentley,pgmcrater,pgmedge,pgmenhance,pgmhist,pgmkernel,pgmnoise,pgmnorm,pgmoil,pgmramp,pgmslice,pgmtexture,pgmtofs,pgmtolispm,pgmtopbm,pgmtoppm,pgrep,php,php5,pi1toppm,pi3topbm,pic,pic2graph,pico,piconv,pidstat,pinky,pip,pjtoppm,pkill,pl2pm,plog,pmap,pngtopnm,pnmalias,pnmarith,pnmcat,pnmcolormap,pnmcomp,pnmconvol,pnmcrop,pnmcut,pnmdepth,pnmenlarge,pnmfile,pnmflip,pnmgamma,pnmhisteq,pnmhistmap,pnmindex,pnminterp,pnminterp-gen,pnminvert,pnmmargin,pnmmontage,pnmnlfilt,pnmnoraw,pnmnorm,pnmpad,pnmpaste,pnmpsnr,pnmquant,pnmremap,pnmrotate,pnmscale,pnmscalefixed,pnmshear,pnmsmooth,pnmsplit,pnmtile,pnmtoddif,pnmtofiasco,pnmtofits,pnmtojpeg,pnmtopalm,pnmtoplainpnm,pnmtopng,pnmtops,pnmtorast,pnmtorle,pnmtosgi,pnmtosir,pnmtotiff,pnmtotiffcmyk,pnmtoxwd,pod2html,pod2latex,pod2man,pod2text,pod2usage,podchecker,podselect,poff,pon,POST,post-grohtml,ppm3d,ppmbrighten,ppmchange,ppmcie,ppmcolormask,ppmcolors,ppmdim,ppmdist,ppmdither,ppmfade,ppmflash,ppmforge,ppmhist,ppmlabel,ppmmake,ppmmix,ppmnorm,ppmntsc,ppmpat,ppmquant,ppmquantall,ppmqvga,ppmrainbow,ppmrelief,ppmshadow,ppmshift,ppmspread,ppmtoacad,ppmtobmp,ppmtoeyuv,ppmtogif,ppmtoicr,ppmtoilbm,ppmtojpeg,ppmtoleaf,ppmtolj,ppmtomap,ppmtomitsu,ppmtompeg,ppmtoneo,ppmtopcx,ppmtopgm,ppmtopi1,ppmtopict,ppmtopj,ppmtopuzz,ppmtorgb3,ppmtosixel,ppmtotga,ppmtouil,ppmtowinicon,ppmtoxpm,ppmtoyuv,ppmtoyuvsplit,ppmtv,pr,preconv,pre-grohtml,prename,print,printafm,printenv,printerbanner,printf,prove,prtstat,prune,ps2ascii,ps2epsi,ps2pdf,ps2pdf12,ps2pdf13,ps2pdf14,ps2pdfwr,ps2ps,ps2ps2,ps2txt,psbook,psed,psfaddtable,psfgettable,psfstriptable,psfxtable,psidtopgm,psmerge,psnup,psresize,psselect,pstopnm,pstops,pstree,pstree.x11,pstruct,ptar,ptardiff,ptx,pwdx,py3_compilefiles,pycentral,pyclean,pycompile,py_compilefiles,pydoc,pydoc2.6,pydoc3,pydoc3.1,pygettext,pygettext2.6,pygettext3,pygettext3.1,pyhtmlizer,python,python2,python2.6,python3,python3.1,pyversions,qrttoppm,rasttopnm,rawtopgm,rawtoppm,rcp,red,refer,rename,rename.ul,renice,replace,report-hw,reset,resolveip,resolve_stack_dump,rev,rgb3toppm,rgrep,rletopnm,rlogin,rmcp_ping,roff2dvi,roff2html,roff2pdf,roff2ps,roff2text,roff2x,routef,routel,rpcclient,rpcinfo,rpm,rpm2cpio,rpmbuild,rpmdb,rpmgraph,rpmquery,rpmsign,rpmverify,rrdcgi,rrdtool,rrdupdate,rsh,rsync,rtstat,runcon,run-mailcap,rview,rvim,s2p,sadf,sar,sar.sysstat,savelog,sbigtopgm,sccmap,scp,screen,screendump,screen-launcher,screen-profiles-status,script,scriptreplay,sdiff,search,searchd,see,select-editor,sendsms,sensible-browser,sensible-editor,sensible-pager,sensors,sensors-conf-convert,seq,service,setarch,setkeycodes,setleds,setlogcons,setmetamode,setpci,setsid,setterm,sftp,sg,sgitopnm,sha1sum,sha224sum,sha256sum,sha384sum,sha512sum,shasum,showchar,showconsolefont,showkey,shred,shuf,sirtopnm,skill,slabtop,sldtoppm,slogin,smbcacls,smbclient,smbcquotas,smbget,smbpasswd,smbspool,smbtar,smbtree,smime_keys,snice,snmpbulkget,snmpbulkwalk,snmpconf,snmpdelta,snmpdf,snmpget,snmpgetnext,snmpinform,snmpkey,snmpnetstat,snmpset,snmpstatus,snmptable,snmptest,snmptranslate,snmptrap,snmpusm,snmpvacm,snmpwalk,soelim,solterm,sort,spctoppm,spelldump,splain,split,splitfont,sputoppm,ssh,ssh-add,ssh-agent,ssh-argv0,ssh-copy-id,sshfs,ssh-keygen,ssh-keyscan,ssh-vulnkey,st4topgm,stat,strace,stream,sudo,sudoedit,sum,svn,svnadmin,svnauthz-validate,svndumpfilter,svnlook,svnmucc,svn-populate-node-origins-index,svnserve,svnsync,svnversion,tabs,tac,tail,tap2deb,tap2rpm,tapconvert,tasksel,taskset,tbl,tee,telnet,telnet.netkit,test,testparm,testparm.samba3,tfmtodit,tgatoppm,thinkjettopbm,tic,tifftopnm,time,tload,toe,top,touch,tput,tr,tracepath,tracepath6,traceroute6,traceroute6.iputils,traptoemail,tred,trial,troff,truncate,tset,tsort,tty,twistd,twopi,tzselect,ubuntu-bug,ubuntu-support-status,ucf,ucfq,ucfr,ucs2any,ul,unattended-upgrade,unattended-upgrades,unexpand,unflatten,unicode_stop,uniq,unlink,unlzma,unshare,unzip,unzipsfx,update-alternatives,updatedb,updatedb.mlocate,update-mime-database,update-mime-database.real,update-pciids,update-perl-sax-parsers,uptime,usb-devices,users,uuidgen,vi,view,vim,vim.basic,vimdiff,vim.tiny,vimtutor,vmstat,volname,w,w3m,w3mman,wall,watch,wbmptopbm,wc,webalizer,webazolver,wftopfa,wget,whatis,whereis,which,whiptail,who,whoami,winicontoppm,wpa_passphrase,w.procps,write,www-browser,X11,x86_64,x86_64-linux-gnu-cpp,x86_64-linux-gnu-cpp-4.4,xargs,xauth,xbmtopbm,ximtoppm,xpmtoppm,xsubpp,xtotroff,xvminitoppm,xwdtopnm,xxd,ybmtopbm,yes,yuvsplittoppm,yuvtoppm,zabbix_get,zdump,zeisstopnm,zipgrep,zipinfo,zsoelim,,/usr/sbin/:,a2dismod,a2dissite,a2enmod,a2ensite,aa-audit,aa-autodep,aa-complain,aa-decode,aa-enforce,aa-genprof,aa-logprof,aa-status,aa-unconfined,ab,accessdb,addgroup,add-shell,adduser,apache2,apache2ctl,apparmor_status,arp,arpd,atd,audit,autodep,bacula-console,bacula-fd,bandwidthd,bcrelay,biosdecode,brctl,bsmtp,btraceback,chat,check_forensic,checkgid,chgpasswd,chpasswd,chroot,ck-log-system-restart,ck-log-system-start,ck-log-system-stop,complain,console-kit-daemon,cpgr,cppw,cron,cytune,dbconfig-generate-include,dbconfig-load-include,defoma-reconfigure,delgroup,deluser,dmidecode,dpkg-divert,dpkg-preconfigure,dpkg-reconfigure,dpkg-statoverride,e2freefrag,enforce,ethtool,exicyclog,exigrep,exim,exim4,exim_checkaccess,exim_convert4r4,exim_dbmbuild,exim_dumpdb,exim_fixdb,exim_lock,eximstats,exim_tidydb,exinext,exipick,exiqgrep,exiqsumm,exiwhat,fancontrol,fdformat,filefrag,genprof,gmetad,gmond,gnokiid,groupadd,groupdel,groupmod,grpck,grpconv,grpunconv,grub-install,grub-mkconfig,grub-mkdevicemap,grub-probe,grub-reboot,grub-set-default,grub-setup,gss_clnt_send_err,gss_destroy_creds,htcacheclean,httxt2dbm,iconvconfig,install-info,install-sgmlcatalog,invoke-rc.d,ip6tables-apply,ipmievd,iptables-apply,irqbalance,isadump,isaset,laptop-detect,ldattach,libgraphviz4-config-update,locale-gen,login.radius,logprof,logresolve,logrotate,lsusb,make-ssl-cert,mgnokiidev,mkinitramfs,mkinitramfs-kpkg,mklost+found,munin-node,munin-node-configure,munin-run,mysqld,mysqlmanager,nagios3,nagios3stats,newusers,nfsstat,nologin,ntop,ntpd,ntpdate,ntpdate-debian,openntpd,openvpn,openvpn-vulnkey,ownership,pam-auth-update,pam_getenv,paperconfig,popcon-largest-unused,popularity-contest,pppconfig,pppd,pppdump,pppoeconf,pppoe-discovery,pppstats,pptpctrl,pptpd,pwck,pwconv,pwmconfig,pwunconv,radacct,radexample,radlogin,radstatus,ramsize,rdev,readprofile,remove-shell,rmail,rmt,rmt-dump,rmt-tar,rootflags,rotatelogs,rpcdebug,rpc.gssd,rpc.idmapd,rsmtp,rsyslogd,rtcwake,runq,safe_finger,sendmail,sensors-detect,service,setvesablank,snmpd,snmptrapd,spine,split-logfile,sshd,syslog2eximlog,tcpd,tcpdchk,tcpdmatch,tcpdump,try-from,tunelp,tzconfig,ufw,unconfined,update-alternatives,update-bootsystem-insserv,update-ca-certificates,update-catalog,update-exim4.conf,update-exim4.conf.template,update-exim4defaults,update-fonts-alias,update-fonts-dir,update-fonts-scale,update-gdkpixbuf-loaders,update-grub,update-grub2,update-gtk-immodules,update-icon-caches,update-inetd,update-info-dir,update-initramfs,update-locale,update-mime,update-pangox-aliases,update-passwd,update-python-modules,update-rc.d,update-rc.d-insserv,update-usbids,update-xmlcatalog,upgrade-from-grub-legacy,useradd,userdel,usermod,uuidd,validlocale,vcstime,vidmode,vigr,vipw,visudo,vpddecode,vsftpd,xl2tpd,zabbix_server,zic&#10;&#9;&#9;&#9;" /><link rel="home" href="../index.html" title="Netkiller Linux 手札" /><link rel="up" href="distributed-filesystem.html" title="第 75 章 Distributed File Systems" /><link rel="prev" href="moosefs.html" title="4. Moose File System" /><link rel="next" href="ceph.html" title="6. Ceph" /></head><body><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">5. Hadoop - HDFS</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="moosefs.html">上一页</a> </td><th width="60%" align="center">第 75 章 Distributed File Systems</th><td width="20%" align="right"> <a accesskey="n" href="ceph.html">下一页</a></td></tr></table><hr /></div><table xmlns="" width="100%" border="0"><tr><td align="left"><a href="http://netkiller.github.io/">Home</a> |
                <a href="http://netkiller.sourceforge.net/">Mirror</a> |
                <a href="/search.html">Search</a></td><td><div id="bdshare" class="bdshare_t bds_tools_32 get-codes-bdshare"><a class="bds_fbook"></a><a class="bds_twi"></a><a class="bds_ms"></a><a class="bds_msn"></a><a class="bds_buzz"></a><a class="bds_linkedin"></a><a class="bds_deli"></a><a class="bds_qzone"></a><a class="bds_qq"></a><a class="bds_tqq"></a><a class="bds_tqf"></a><a class="bds_tsina"></a><a class="bds_baidu"></a><a class="bds_renren"></a><a class="bds_t163"></a><a class="bds_tfh"></a><a class="bds_ty"></a><a class="bds_s51"></a><a class="bds_douban"></a><a class="bds_hi"></a><a class="bds_tieba"></a><a class="bds_tsohu"></a><a class="bds_zx"></a><a class="bds_tuita"></a><span class="bds_more"></span><a class="shareCount"></a></div><script type="text/javascript" id="bdshare_js" data="type=tools"></script><script type="text/javascript" id="bdshell_js"></script><script type="text/javascript">
	document.getElementById("bdshell_js").src = "http://bdimg.share.baidu.com/static/js/shell_v2.js?cdnversion=" + new Date().getHours();
</script></td><td><form id="searchbox_008589143145807374698:f5uprauilyy" action="/search.html"><input type="hidden" name="cx" value="008589143145807374698:f5uprauilyy" /><input type="hidden" name="cof" value="FORID:11" /><input name="q" type="text" size="25" style="border-top-width: 1px; border-right-width: 1px; border-bottom-width: 1px; border-left-width: 1px; border-top-style: solid; border-right-style: solid; border-bottom-style: solid; border-left-style: solid; border-top-color: rgb(126, 157, 185); border-right-color: rgb(126, 157, 185); border-bottom-color: rgb(126, 157, 185); border-left-color: rgb(126, 157, 185); padding-top: 2px; padding-right: 2px; padding-bottom: 2px; padding-left: 2px; background-image: url(http://www.google.com/cse/intl/en/images/google_custom_search_watermark.gif); background-attachment: initial; background-origin: initial; background-clip: initial; background-color: rgb(255, 255, 255); background-position: 0% 50%; background-repeat: no-repeat no-repeat; " /><input type="submit" name="sa" value="Search" /><input name="siteurl" type="hidden" value="http://netkiller.sourceforge.net/" /></form><script type="text/javascript" src="http://www.google.com/coop/cse/brand?form=searchbox_008589143145807374698%3Af5uprauilyy"></script></td></tr></table><div class="section" title="5. Hadoop - HDFS"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="hdfs"></a>5. Hadoop - HDFS</h2></div></div></div><p>http://hadoop.apache.org/</p><div class="section" title="5.1. 单机安装"><div class="titlepage"><div><div><h3 class="title"><a id="idp12083808"></a>5.1. 单机安装</h3></div></div></div><p>这种安装方式仅仅适用于做实验，快速搭建Hadoop环境，不适合生产环境。</p><p>Ubuntu 环境</p><pre class="screen">
$ sudo apt-get install openjdk-7-jre
		</pre><div class="procedure" title="过程 75.1. Master configure"><a id="idp12085632"></a><p class="title"><strong>过程 75.1. Master configure</strong></p><ol class="procedure" type="1"><li class="step" title="步骤 1"><p>Download and Installing Software</p><pre class="screen">
				
$ cd /usr/local/src/
$ wget http://apache.etoak.com/hadoop/core/hadoop-0.20.0/hadoop-0.20.0.tar.gz
$ tar zxvf hadoop-0.20.0.tar.gz
$ sudo cp -r hadoop-0.20.0 ..
$ sudo ln -s hadoop-0.20.0 hadoop
$ cd hadoop
				
				</pre></li><li class="step" title="步骤 2"><p>Configuration</p><p>hadoop-env.sh</p><pre class="screen">
				
$ vim conf/hadoop-env.sh
export JAVA_HOME=/usr
				
				</pre><p>conf/core-site.xml</p><pre class="screen">
				
$ vim conf/core-site.xml

&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;fs.default.name&lt;/name&gt;
    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
				
				</pre><p>conf/hdfs-site.xml</p><pre class="screen">
				
$ vim conf/hdfs-site.xml

&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
				
				</pre><p>conf/mapred-site.xml</p><pre class="screen">
				
$ vim conf/mapred-site.xml

&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;mapred.job.tracker&lt;/name&gt;
    &lt;value&gt;localhost:9001&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
				
				</pre></li><li class="step" title="步骤 3"><p>Setup passphraseless ssh</p><pre class="screen">
				
Now check that you can ssh to the localhost without a passphrase:
$ ssh localhost

If you cannot ssh to localhost without a passphrase, execute the following commands:
$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
				
				</pre></li><li class="step" title="步骤 4"><p>Execution</p><pre class="screen">
 Format a new distributed-filesystem:
$ bin/hadoop namenode -format

Start the hadoop daemons:
$ bin/start-all.sh

When you're done, stop the daemons with:
$ bin/stop-all.sh
				</pre></li><li class="step" title="步骤 5"><p>Monitor</p><p>Browse the web interface for the NameNode and the JobTracker; by default they are available at:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>NameNode - http://localhost:50070/</p></li><li class="listitem"><p>JobTracker - http://localhost:50030/</p></li></ul></div></li><li class="step" title="步骤 6"><p>Test</p><pre class="screen">
				
$ bin/hadoop dfs -mkdir test
$ echo helloworld &gt; testfile
$ bin/hadoop dfs -copyFromLocal testfile test/
$ bin/hadoop dfs -ls
Found 1 items
drwxr-xr-x   - neo supergroup          0 2009-07-10 14:18 /user/neo/test

$ bin/hadoop dfs -ls test

$ bin/hadoop dfs –cat test/file
				
				</pre></li></ol></div><div class="procedure" title="过程 75.2. slave config"><a id="idp12098912"></a><p class="title"><strong>过程 75.2. slave config</strong></p><ol class="procedure" type="1"><li class="step" title="步骤 1"><p>SSH</p><pre class="screen">
				
$ scp neo@master:~/.ssh/id_dsa.pub .ssh/master.pub
$ cat .ssh/master.pub &gt;&gt; .ssh/authorized_keys
				
				</pre></li><li class="step" title="步骤 2"><p>Hadoop</p><pre class="screen">
				
$ scp neo@master:/usr/local/hadoop /usr/local/hadoop
				
				</pre></li></ol></div></div><div class="section" title="5.2. 分布式安装"><div class="titlepage"><div><div><h3 class="title"><a id="idp12101968"></a>5.2. 分布式安装</h3></div></div></div><div class="literallayout"><p><br />
HDFS:<br />
      NameNode  ：管理节点<br />
      DataNode  ：数据节点<br />
      SecondaryNamenode : 数据源信息备份整理节点<br />
<br />
MapReduce<br />
       JobTracker  ：任务管理节点<br />
       Tasktracker ：任务运行节点<br />
		</p></div><div class="section" title="5.2.1. 准备工作"><div class="titlepage"><div><div><h4 class="title"><a id="idp12103360"></a>5.2.1. 准备工作</h4></div></div></div><p>准备4台服务器，操作系统为 Centos 6.4 最小化安装</p><div class="literallayout"><p><br />
NameNode  	192.168.2.10	hostname namenode<br />
DataNode    192.168.2.11	hostname:datanode1<br />
DataNode    192.168.2.12	hostname:datanode2<br />
<br />
JobTracker  192.168.2.10	(也可单独配置一台,也可以与NameNode公用，这里只用到了HDFS，这台可有可无，准备上面4台即可)<br />
TaskTracker					(与DataNode共用)<br />
			</p></div><p>设置网络使其可以互访，然后关闭防火墙与selinux</p><pre class="screen">
# yum update -y
# lokkit --disabled --selinux=disabled
			</pre><p>Hadoop 重要的端口</p><div class="literallayout"><p><br />
1.Job Tracker 管理界面： 50030<br />
2.HDFS 管理界面 ：		 50070<br />
3.HDFS通信端口：		 9000<br />
4.MapReduce通信端口：	 9001<br />
			</p></div><div class="procedure" title="过程 75.3. Hadoop - 准备工作"><a id="idp12107456"></a><p class="title"><strong>过程 75.3. Hadoop - 准备工作</strong></p><ol class="procedure" type="1"><li class="step" title="步骤 1"><p>为所有服务器安装Java运行环境</p><p>以 CentOS 6.4 为例</p><pre class="screen">
# yum install java-1.7.0-openjdk
					</pre></li><li class="step" title="步骤 2"><p>在所有服务器上安装 Hadoop</p><p>安装方案有下面两种 RPM与YUM，选择其中一种</p><pre class="screen">
# rpm -ivh http://ftp.cuhk.edu.hk/pub/packages/apache.org/hadoop/common/hadoop-1.1.2/hadoop-1.1.2-1.x86_64.rpm
Retrieving http://ftp.cuhk.edu.hk/pub/packages/apache.org/hadoop/common/hadoop-1.1.2/hadoop-1.1.2-1.x86_64.rpm
Preparing...                ########################################### [100%]
   1:hadoop                 ########################################### [100%]
					</pre><pre class="screen">
yum localinstall http://ftp.cuhk.edu.hk/pub/packages/apache.org/hadoop/common/hadoop-1.1.2/hadoop-1.1.2-1.x86_64.rpm
					</pre><p>如果网络比较慢，可以使用Wget或axel下载后安装</p><pre class="screen">
wget http://ftp.cuhk.edu.hk/pub/packages/apache.org/hadoop/common/hadoop-1.1.2/hadoop-1.1.2-1.x86_64.rpm
yum localinstall hadoop-1.1.2-1.x86_64.rpm
					</pre><p>Hadoop 用户</p><pre class="screen">
# cat /etc/passwd | grep Hadoop
mapred:x:202:123:Hadoop MapReduce:/tmp:/bin/bash
hdfs:x:201:123:Hadoop HDFS:/tmp:/bin/bash
					</pre></li><li class="step" title="步骤 3"><p>配置/etc/hosts文件</p><pre class="screen">
					
cat &gt;&gt; /etc/hosts &lt;&lt;EOD

###############################
# Hadoop Host
###############################
#NameNode
192.168.2.10 	namenode.example.com

#DataNode
192.168.2.11 	datanode1.example.com
192.168.2.12 	datanode2.example.com

EOD
					
					</pre></li><li class="step" title="步骤 4"><p>生成其密钥</p><pre class="screen">
					
# ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
cc:6f:30:76:82:28:96:13:c8:e6:bc:d7:5b:2d:11:d7 root@images-upload
The key's randomart image is:
+--[ RSA 2048]----+
|                 |
|..        .      |
|.o.    . . E     |
|+  o . +o        |
| o= . ..S .      |
| ..o.  .o*       |
| . . . o .o      |
|  .   o ..       |
|     .           |
+-----------------+
					
					</pre></li><li class="step" title="步骤 5"><p>植入公钥证书</p><p>向DataNode节点所有的服务器植入公钥证书</p><pre class="screen">
					
ssh-copy-id root@datanode1.example.com
ssh-copy-id root@datanode2.example.com
					
					</pre><p>只需要输入yes后，再输入密码即可完成公钥证书的植入。过程类似下面：</p><pre class="screen">
# ssh-copy-id root@datanode1.example.com
The authenticity of host 'datanode1.example.com (192.168.2.11)' can't be established.
RSA key fingerprint is f1:0b:b1:63:1a:f6:ac:a3:da:4f:14:b5:f0:cc:df:67.
Are you sure you want to continue connecting (yes/no)? yes 输入yes
Warning: Permanently added 'datanode1.example.com' (RSA) to the list of known hosts.
root@datanode1.example.com's password: 输入密码
Now try logging into the machine, with "ssh 'root@datanode1.example.com'", and check in:

  .ssh/authorized_keys

to make sure we haven't added extra keys that you weren't expecting.

# ssh-copy-id root@datanode2.example.com
The authenticity of host 'datanode2.example.com (192.168.2.12)' can't be established.
RSA key fingerprint is f1:0b:b1:63:1a:f6:ac:a3:da:4f:14:b5:f0:cc:df:67.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'datanode2.example.com,192.168.2.12' (RSA) to the list of known hosts.
root@datanode2.example.com's password:
Now try logging into the machine, with "ssh 'root@datanode2.example.com'", and check in:

  .ssh/authorized_keys

to make sure we haven't added extra keys that you weren't expecting.

					</pre><p>完成后测试登陆，如果没有提示密码直接进入表示正确</p><pre class="screen">
# ssh root@datanode1.example.com
# exit
					</pre></li></ol></div></div><div class="section" title="5.2.2. NameNode 配置名称节点"><div class="titlepage"><div><div><h4 class="title"><a id="idp12122208"></a>5.2.2. NameNode 配置名称节点</h4></div></div></div><p>配置文件</p><pre class="screen">
core-site.xml	 common属性配置
hdfs-site.xml    HDFS属性配置
mapred-site.xml  MapReduce属性配置
hadoop-env.sh    hadooop 环境变量配置
			</pre><div class="procedure" title="过程 75.4. Hadoop - NameNode"><a id="idp12123568"></a><p class="title"><strong>过程 75.4. Hadoop - NameNode</strong></p><ol class="procedure" type="1"><li class="step" title="步骤 1"><p>配置文件 hadoop-env.sh</p><p>将 /usr/java/default 改为 /usr</p><pre class="screen">
# cp hadoop-env.sh hadoop-env.sh.original
# sed -i "s:/usr/java/default:/usr:" hadoop-env.sh
					</pre></li><li class="step" title="步骤 2"><p>配置文件 core-site.xml</p><pre class="screen">
					
# cp core-site.xml core-site.xml.original

&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
         &lt;name&gt;fs.default.name&lt;/name&gt;
         &lt;value&gt;hdfs://namenode.example.com:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
         &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
         &lt;value&gt;/var/tmp/hadoop&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
					
					</pre><p>fs.default.name: NameNode的URI。hdfs://主机名:端口/ </p><p>hadoop.tmp.dir: Hadoop的默认临时路径， </p></li><li class="step" title="步骤 3"><p>配置文件 mapred-site.xml </p><pre class="screen">
					
# cp mapred-site.xml mapred-site.xml.original
&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapred.job.tracker&lt;/name&gt;
        &lt;value&gt;namenode.example.com:9001&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapred.local.dir&lt;/name&gt;
        &lt;value&gt;/var/tmp/hadoop&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
					
					</pre><p>mapred.job.tracker: JobTracker的主机和端口。</p></li><li class="step" title="步骤 4"><p>配置文件 hdfs-site.xml </p><pre class="screen">
					
# cp hdfs-site.xml hdfs-site.xml.original

&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.name.dir&lt;/name&gt;
        &lt;value&gt;/var/hadoop/name1&lt;/value&gt;
        &lt;description&gt;  &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.data.dir&lt;/name&gt;
        &lt;value&gt;/var/hadoop/hdfs/data1&lt;/value&gt;
        &lt;description&gt; &lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
					
					</pre><pre class="screen">
dfs.name.dir: NameNode持久存储名字空间及事务日志的本地文件系统路径。 当这个值是一个逗号分割的目录列表时，nametable数据将会被复制到所有目录中做冗余备份。
2）   dfs.data.dir是DataNode存放块数据的本地文件系统路径，逗号分割的列表。 当这个值是逗号分割的目录列表时，数据将被存储在所有目录下，通常分布在不同设备上。
3）dfs.replication是数据需要备份的数量，默认是3，如果此数大于集群的机器数会出错。
					</pre></li><li class="step" title="步骤 5"><p>配置masters和slaves主从结点</p><p>备份masters与slaves配置文件 </p><pre class="screen">
 cp masters masters.original
 cp slaves slaves.original
					</pre><pre class="screen">
					
cat &gt; /etc/hadoop/masters &lt;&lt;EOD
namenode.example.com
EOD
					
					</pre><pre class="screen">
					
cat &gt; /etc/hadoop/slaves &lt;&lt;EOD
datanode1.example.com
datanode2.example.com
EOD
					
					</pre></li><li class="step" title="步骤 6"><p>复制配置文件</p><pre class="screen">
# cd /etc/hadoop/
# scp hadoop-env.sh core-site.xml mapred-site.xml hdfs-site.xml masters slaves root@datanode1.example.com:/etc/hadoop/
# scp hadoop-env.sh core-site.xml mapred-site.xml hdfs-site.xml masters slaves root@datanode2.example.com:/etc/hadoop/
					</pre><p>控制台输出类似下面表示复制成功。</p><pre class="screen">
# scp hadoop-env.sh core-site.xml mapred-site.xml hdfs-site.xml masters slaves root@datanode1.example.com:/etc/hadoop/
hadoop-env.sh                                                                          100% 2116     2.1KB/s   00:00
core-site.xml                                                                          100%  412     0.4KB/s   00:00
mapred-site.xml                                                                        100%  406     0.4KB/s   00:00
hdfs-site.xml                                                                          100%  595     0.6KB/s   00:00
masters                                                                                100%   21     0.0KB/s   00:00
slaves
					</pre><p>将 NameNode 上的配置文件复制给 DataNode</p></li><li class="step" title="步骤 7"><p>启动 Hadoop </p><p>创建工作目录 </p><pre class="screen">
# mkdir /var/hadoop/
# mkdir /var/hadoop/name{1,2}
# su - hdfs -c  "mkdir -p  /var/hadoop/hdfs/data{1,2}"
					</pre><pre class="screen">
# hadoop namenode -format
13/04/23 14:35:33 INFO namenode.NameNode: STARTUP_MSG:
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = namenode.example.com/192.168.2.10
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 1.1.2
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.1 -r 1440782; compiled by 'hortonfo' on Thu Jan 31 02:06:43 UTC 2013
************************************************************/
Re-format filesystem in /var/hadoop/name1 ? (Y or N) Y
13/04/23 14:35:37 INFO util.GSet: VM type       = 64-bit
13/04/23 14:35:37 INFO util.GSet: 2% max memory = 2.475 MB
13/04/23 14:35:37 INFO util.GSet: capacity      = 2^18 = 262144 entries
13/04/23 14:35:37 INFO util.GSet: recommended=262144, actual=262144
13/04/23 14:35:37 INFO namenode.FSNamesystem: fsOwner=root
13/04/23 14:35:37 INFO namenode.FSNamesystem: supergroup=supergroup
13/04/23 14:35:37 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/04/23 14:35:37 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/04/23 14:35:37 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/04/23 14:35:38 INFO namenode.NameNode: Caching file names occuring more than 10 times
13/04/23 14:35:38 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/04/23 14:35:38 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/var/hadoop/name1/current/edits
13/04/23 14:35:38 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/var/hadoop/name1/current/edits
13/04/23 14:35:38 INFO common.Storage: Storage directory /var/hadoop/name1 has been successfully formatted.
13/04/23 14:35:38 INFO common.Storage: Image file of size 110 saved in 0 seconds.
13/04/23 14:35:38 INFO namenode.FSEditLog: closing edit log: position=4, editlog= /var/hadoop/name2/current/edits
13/04/23 14:35:38 INFO namenode.FSEditLog: close success: truncate to 4, editlog= /var/hadoop/name2/current/edits
13/04/23 14:35:38 INFO common.Storage: Storage directory  /var/hadoop/name2 has been successfully formatted.
13/04/23 14:35:38 INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at namenode.example.com/192.168.2.10
************************************************************/
					</pre><pre class="screen">
# chown hdfs:hadoop -R /var/hadoop
					</pre><pre class="screen">
# /etc/init.d/hadoop-namenode start
# /etc/init.d/hadoop-datanode start
					</pre></li></ol></div><p>http://192.168.2.10:50070/</p></div><div class="section" title="5.2.3. DataNode 配置数据节点"><div class="titlepage"><div><div><h4 class="title"><a id="idp12145376"></a>5.2.3. DataNode 配置数据节点</h4></div></div></div><div class="procedure" title="过程 75.5. Hadoop - DataNode"><a id="idp12145808"></a><p class="title"><strong>过程 75.5. Hadoop - DataNode</strong></p><ol class="procedure" type="1"><li class="step" title="步骤 1"><p>创建hadoop数据存储目录</p><pre class="screen">
					
mkdir /var/hadoop/
chown hdfs:hadoop -R /var/hadoop
su - hdfs -c  "mkdir -p  /var/hadoop/hdfs/data1"
					
					</pre></li><li class="step" title="步骤 2"><p>启动  Hadoop</p><pre class="screen">
					
# /etc/init.d/hadoop-datanode start
					
					</pre></li></ol></div></div><div class="section" title="5.2.4. Hadoop UI (WEB界面)"><div class="titlepage"><div><div><h4 class="title"><a id="idp12148960"></a>5.2.4. Hadoop UI (WEB界面)</h4></div></div></div><p>常用访问页面</p><div class="literallayout"><p><br />
1. HDFS 界面<br />
        http://hostname:50070<br />
2. MapReduce 管理界面<br />
        http://hostname:50030<br />
        	</p></div></div><div class="section" title="5.2.5. 测试Hadoop"><div class="titlepage"><div><div><h4 class="title"><a id="idp12150528"></a>5.2.5. 测试Hadoop</h4></div></div></div><p>将install.log文件拷贝到分布式文件系统</p><pre class="screen">
hadoop fs -mkdir test
hadoop fs -put install.log test
			</pre><p>显示文件内容</p><pre class="screen">
# hadoop dfs -cat test/install.log
			</pre><p>查看目录结构</p><pre class="screen">
# hadoop dfs -ls
Found 1 items
drwxr-xr-x   - root supergroup          0 2013-04-23 15:20 /user/root/test
[root@namenode ~]# hadoop dfs -ls test
Found 1 items
-rw-r--r--   2 root supergroup      10278 2013-04-23 15:20 /user/root/test/install.log
			</pre></div></div><div class="section" title="5.3. 二进制包安装"><div class="titlepage"><div><div><h3 class="title"><a id="idp12153824"></a>5.3. 二进制包安装</h3></div></div></div><div class="section" title="5.3.1. 安装 JRE"><div class="titlepage"><div><div><h4 class="title"><a id="hdfs.jre"></a>5.3.1. 安装 JRE</h4></div></div></div><p>如果你使用的是Oracle网站下载的JRE需要配置 java classpath</p><pre class="screen">
			
$ sudo vim /etc/profile.d/java.sh
################################################
### Java environment by neo
################################################
export JAVA_HOME=/usr
export JRE_HOME=/usr
export PATH=$PATH:/usr/local/apache-tomcat/bin/:/usr/local/jetty-6.1.18/bin:/usr/local/apache-nutch/bin
export CLASSPATH="./:/usr/share/java/:/usr/local/apache-solr/example/multicore/lib"
export JAVA_OPTS="-Xms128m -Xmx1024m"
			
			</pre></div><div class="section" title="5.3.2. 安装 Hadoop"><div class="titlepage"><div><div><h4 class="title"><a id="idp12156176"></a>5.3.2. 安装 Hadoop</h4></div></div></div><pre class="screen">
wget http://apache.communilink.net/hadoop/common/hadoop-1.1.2/hadoop-1.1.2-bin.tar.gz
			</pre><p>启动与停止 hadoop</p><div class="literallayout"><p><br />
启动/关闭所有服务 start-all.sh/stop-all.sh<br />
启动/关闭HDFS: start-dfs.sh/stop-dfs.sh<br />
启动/关闭MapReduce:  start-mapred.sh/stop-mapred.sh<br />
			</p></div></div><div class="section" title="5.3.3. 创建用户"><div class="titlepage"><div><div><h4 class="title"><a id="idp12158496"></a>5.3.3. 创建用户</h4></div></div></div><p>如果使用tar包安装，需要创建用户，这里请忽略</p><pre class="screen">
# adduser hadoop
			</pre><p></p><pre class="screen">
			</pre></div></div><div class="section" title="5.4. FAQ"><div class="titlepage"><div><div><h3 class="title"><a id="idp12160464"></a>5.4. FAQ</h3></div></div></div><div class="section" title="5.4.1. hadoop-1.1.2-1.x86_64.rpm 包含哪些文件内容"><div class="titlepage"><div><div><h4 class="title"><a id="idp12160848"></a>5.4.1. hadoop-1.1.2-1.x86_64.rpm 包含哪些文件内容</h4></div></div></div><p>查看安装文件</p><pre class="screen">
# rpm -ql hadoop-1.1.2-1
/etc/hadoop/capacity-scheduler.xml
/etc/hadoop/configuration.xsl
/etc/hadoop/core-site.xml
/etc/hadoop/fair-scheduler.xml
/etc/hadoop/hadoop-env.sh
/etc/hadoop/hadoop-metrics2.properties
/etc/hadoop/hadoop-policy.xml
/etc/hadoop/hdfs-site.xml
/etc/hadoop/log4j.properties
/etc/hadoop/mapred-queue-acls.xml
/etc/hadoop/mapred-site.xml
/etc/hadoop/masters
/etc/hadoop/slaves
/etc/hadoop/ssl-client.xml.example
/etc/hadoop/ssl-server.xml.example
/etc/hadoop/taskcontroller.cfg
/etc/rc.d/init.d
/etc/rc.d/init.d/hadoop-datanode
/etc/rc.d/init.d/hadoop-historyserver
/etc/rc.d/init.d/hadoop-jobtracker
/etc/rc.d/init.d/hadoop-namenode
/etc/rc.d/init.d/hadoop-secondarynamenode
/etc/rc.d/init.d/hadoop-tasktracker
/usr
/usr/bin
/usr/bin/hadoop
/usr/bin/task-controller
/usr/include
/usr/include/hadoop
/usr/include/hadoop/Pipes.hh
/usr/include/hadoop/SerialUtils.hh
/usr/include/hadoop/StringUtils.hh
/usr/include/hadoop/TemplateFactory.hh
/usr/lib
/usr/lib64
/usr/lib64/libhadoop.a
/usr/lib64/libhadoop.la
/usr/lib64/libhadoop.so
/usr/lib64/libhadoop.so.1
/usr/lib64/libhadoop.so.1.0.0
/usr/lib64/libhadooppipes.a
/usr/lib64/libhadooputils.a
/usr/lib64/libhdfs.a
/usr/lib64/libhdfs.la
/usr/lib64/libhdfs.so
/usr/lib64/libhdfs.so.0
/usr/lib64/libhdfs.so.0.0.0
/usr/libexec
/usr/libexec/hadoop-config.sh
/usr/libexec/jsvc.amd64
/usr/man
/usr/native
/usr/sbin
/usr/sbin/hadoop-create-user.sh
/usr/sbin/hadoop-daemon.sh
/usr/sbin/hadoop-daemons.sh
/usr/sbin/hadoop-setup-applications.sh
/usr/sbin/hadoop-setup-conf.sh
/usr/sbin/hadoop-setup-hdfs.sh
/usr/sbin/hadoop-setup-single-node.sh
/usr/sbin/hadoop-validate-setup.sh
/usr/sbin/rcc
/usr/sbin/slaves.sh
/usr/sbin/start-all.sh
/usr/sbin/start-balancer.sh
/usr/sbin/start-dfs.sh
/usr/sbin/start-jobhistoryserver.sh
/usr/sbin/start-mapred.sh
/usr/sbin/stop-all.sh
/usr/sbin/stop-balancer.sh
/usr/sbin/stop-dfs.sh
/usr/sbin/stop-jobhistoryserver.sh
/usr/sbin/stop-mapred.sh
/usr/sbin/update-hadoop-env.sh
/usr/share
/usr/share/doc
/usr/share/doc/hadoop
/usr/share/doc/hadoop/CHANGES.txt
/usr/share/doc/hadoop/LICENSE.txt
/usr/share/doc/hadoop/NOTICE.txt
/usr/share/doc/hadoop/README.txt
/usr/share/hadoop
/usr/share/hadoop/contrib
/usr/share/hadoop/contrib/datajoin
/usr/share/hadoop/contrib/datajoin/hadoop-datajoin-1.1.2.jar
/usr/share/hadoop/contrib/failmon
/usr/share/hadoop/contrib/failmon/hadoop-failmon-1.1.2.jar
/usr/share/hadoop/contrib/gridmix
/usr/share/hadoop/contrib/gridmix/hadoop-gridmix-1.1.2.jar
/usr/share/hadoop/contrib/hdfsproxy
/usr/share/hadoop/contrib/hdfsproxy/README
/usr/share/hadoop/contrib/hdfsproxy/bin
/usr/share/hadoop/contrib/hdfsproxy/bin/hdfsproxy
/usr/share/hadoop/contrib/hdfsproxy/bin/hdfsproxy-config.sh
/usr/share/hadoop/contrib/hdfsproxy/bin/hdfsproxy-daemon.sh
/usr/share/hadoop/contrib/hdfsproxy/bin/hdfsproxy-daemons.sh
/usr/share/hadoop/contrib/hdfsproxy/bin/hdfsproxy-slaves.sh
/usr/share/hadoop/contrib/hdfsproxy/bin/start-hdfsproxy.sh
/usr/share/hadoop/contrib/hdfsproxy/bin/stop-hdfsproxy.sh
/usr/share/hadoop/contrib/hdfsproxy/build.xml
/usr/share/hadoop/contrib/hdfsproxy/conf
/usr/share/hadoop/contrib/hdfsproxy/conf/configuration.xsl
/usr/share/hadoop/contrib/hdfsproxy/conf/hdfsproxy-default.xml
/usr/share/hadoop/contrib/hdfsproxy/conf/hdfsproxy-env.sh
/usr/share/hadoop/contrib/hdfsproxy/conf/hdfsproxy-env.sh.template
/usr/share/hadoop/contrib/hdfsproxy/conf/hdfsproxy-hosts
/usr/share/hadoop/contrib/hdfsproxy/conf/log4j.properties
/usr/share/hadoop/contrib/hdfsproxy/conf/ssl-server.xml
/usr/share/hadoop/contrib/hdfsproxy/conf/tomcat-forward-web.xml
/usr/share/hadoop/contrib/hdfsproxy/conf/tomcat-web.xml
/usr/share/hadoop/contrib/hdfsproxy/conf/user-certs.xml
/usr/share/hadoop/contrib/hdfsproxy/conf/user-permissions.xml
/usr/share/hadoop/contrib/hdfsproxy/hdfsproxy-2.0.jar
/usr/share/hadoop/contrib/hdfsproxy/logs
/usr/share/hadoop/contrib/hod
/usr/share/hadoop/contrib/hod/CHANGES.txt
/usr/share/hadoop/contrib/hod/README
/usr/share/hadoop/contrib/hod/bin
/usr/share/hadoop/contrib/hod/bin/VERSION
/usr/share/hadoop/contrib/hod/bin/checknodes
/usr/share/hadoop/contrib/hod/bin/hod
/usr/share/hadoop/contrib/hod/bin/hodcleanup
/usr/share/hadoop/contrib/hod/bin/hodring
/usr/share/hadoop/contrib/hod/bin/ringmaster
/usr/share/hadoop/contrib/hod/bin/verify-account
/usr/share/hadoop/contrib/hod/build.xml
/usr/share/hadoop/contrib/hod/conf
/usr/share/hadoop/contrib/hod/conf/hodrc
/usr/share/hadoop/contrib/hod/config.txt
/usr/share/hadoop/contrib/hod/getting_started.txt
/usr/share/hadoop/contrib/hod/hodlib
/usr/share/hadoop/contrib/hod/hodlib/AllocationManagers
/usr/share/hadoop/contrib/hod/hodlib/AllocationManagers/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/AllocationManagers/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/AllocationManagers/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/AllocationManagers/goldAllocationManager.py
/usr/share/hadoop/contrib/hod/hodlib/AllocationManagers/goldAllocationManager.pyc
/usr/share/hadoop/contrib/hod/hodlib/AllocationManagers/goldAllocationManager.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common
/usr/share/hadoop/contrib/hod/hodlib/Common/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/Common/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/allocationManagerUtil.py
/usr/share/hadoop/contrib/hod/hodlib/Common/allocationManagerUtil.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/allocationManagerUtil.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/desc.py
/usr/share/hadoop/contrib/hod/hodlib/Common/desc.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/desc.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/descGenerator.py
/usr/share/hadoop/contrib/hod/hodlib/Common/descGenerator.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/descGenerator.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/hodsvc.py
/usr/share/hadoop/contrib/hod/hodlib/Common/hodsvc.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/hodsvc.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/logger.py
/usr/share/hadoop/contrib/hod/hodlib/Common/logger.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/logger.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/miniHTMLParser.py
/usr/share/hadoop/contrib/hod/hodlib/Common/miniHTMLParser.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/miniHTMLParser.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/nodepoolutil.py
/usr/share/hadoop/contrib/hod/hodlib/Common/nodepoolutil.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/nodepoolutil.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/setup.py
/usr/share/hadoop/contrib/hod/hodlib/Common/setup.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/setup.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/socketServers.py
/usr/share/hadoop/contrib/hod/hodlib/Common/socketServers.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/socketServers.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/tcp.py
/usr/share/hadoop/contrib/hod/hodlib/Common/tcp.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/tcp.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/threads.py
/usr/share/hadoop/contrib/hod/hodlib/Common/threads.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/threads.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/types.py
/usr/share/hadoop/contrib/hod/hodlib/Common/types.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/types.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/util.py
/usr/share/hadoop/contrib/hod/hodlib/Common/util.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/util.pyo
/usr/share/hadoop/contrib/hod/hodlib/Common/xmlrpc.py
/usr/share/hadoop/contrib/hod/hodlib/Common/xmlrpc.pyc
/usr/share/hadoop/contrib/hod/hodlib/Common/xmlrpc.pyo
/usr/share/hadoop/contrib/hod/hodlib/GridServices
/usr/share/hadoop/contrib/hod/hodlib/GridServices/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/GridServices/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/GridServices/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/GridServices/hdfs.py
/usr/share/hadoop/contrib/hod/hodlib/GridServices/hdfs.pyc
/usr/share/hadoop/contrib/hod/hodlib/GridServices/hdfs.pyo
/usr/share/hadoop/contrib/hod/hodlib/GridServices/mapred.py
/usr/share/hadoop/contrib/hod/hodlib/GridServices/mapred.pyc
/usr/share/hadoop/contrib/hod/hodlib/GridServices/mapred.pyo
/usr/share/hadoop/contrib/hod/hodlib/GridServices/service.py
/usr/share/hadoop/contrib/hod/hodlib/GridServices/service.pyc
/usr/share/hadoop/contrib/hod/hodlib/GridServices/service.pyo
/usr/share/hadoop/contrib/hod/hodlib/Hod
/usr/share/hadoop/contrib/hod/hodlib/Hod/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/Hod/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/Hod/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/Hod/hadoop.py
/usr/share/hadoop/contrib/hod/hodlib/Hod/hadoop.pyc
/usr/share/hadoop/contrib/hod/hodlib/Hod/hadoop.pyo
/usr/share/hadoop/contrib/hod/hodlib/Hod/hod.py
/usr/share/hadoop/contrib/hod/hodlib/Hod/hod.pyc
/usr/share/hadoop/contrib/hod/hodlib/Hod/hod.pyo
/usr/share/hadoop/contrib/hod/hodlib/Hod/nodePool.py
/usr/share/hadoop/contrib/hod/hodlib/Hod/nodePool.pyc
/usr/share/hadoop/contrib/hod/hodlib/Hod/nodePool.pyo
/usr/share/hadoop/contrib/hod/hodlib/HodRing
/usr/share/hadoop/contrib/hod/hodlib/HodRing/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/HodRing/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/HodRing/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/HodRing/hodRing.py
/usr/share/hadoop/contrib/hod/hodlib/HodRing/hodRing.pyc
/usr/share/hadoop/contrib/hod/hodlib/HodRing/hodRing.pyo
/usr/share/hadoop/contrib/hod/hodlib/NodePools
/usr/share/hadoop/contrib/hod/hodlib/NodePools/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/NodePools/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/NodePools/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/NodePools/torque.py
/usr/share/hadoop/contrib/hod/hodlib/NodePools/torque.pyc
/usr/share/hadoop/contrib/hod/hodlib/NodePools/torque.pyo
/usr/share/hadoop/contrib/hod/hodlib/RingMaster
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/idleJobTracker.py
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/idleJobTracker.pyc
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/idleJobTracker.pyo
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/ringMaster.py
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/ringMaster.pyc
/usr/share/hadoop/contrib/hod/hodlib/RingMaster/ringMaster.pyo
/usr/share/hadoop/contrib/hod/hodlib/Schedulers
/usr/share/hadoop/contrib/hod/hodlib/Schedulers/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/Schedulers/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/Schedulers/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/Schedulers/torque.py
/usr/share/hadoop/contrib/hod/hodlib/Schedulers/torque.pyc
/usr/share/hadoop/contrib/hod/hodlib/Schedulers/torque.pyo
/usr/share/hadoop/contrib/hod/hodlib/ServiceProxy
/usr/share/hadoop/contrib/hod/hodlib/ServiceProxy/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/ServiceProxy/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/ServiceProxy/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/ServiceProxy/serviceProxy.py
/usr/share/hadoop/contrib/hod/hodlib/ServiceProxy/serviceProxy.pyc
/usr/share/hadoop/contrib/hod/hodlib/ServiceProxy/serviceProxy.pyo
/usr/share/hadoop/contrib/hod/hodlib/ServiceRegistry
/usr/share/hadoop/contrib/hod/hodlib/ServiceRegistry/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/ServiceRegistry/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/ServiceRegistry/__init__.pyo
/usr/share/hadoop/contrib/hod/hodlib/ServiceRegistry/serviceRegistry.py
/usr/share/hadoop/contrib/hod/hodlib/ServiceRegistry/serviceRegistry.pyc
/usr/share/hadoop/contrib/hod/hodlib/ServiceRegistry/serviceRegistry.pyo
/usr/share/hadoop/contrib/hod/hodlib/__init__.py
/usr/share/hadoop/contrib/hod/hodlib/__init__.pyc
/usr/share/hadoop/contrib/hod/hodlib/__init__.pyo
/usr/share/hadoop/contrib/hod/ivy
/usr/share/hadoop/contrib/hod/ivy.xml
/usr/share/hadoop/contrib/hod/ivy/libraries.properties
/usr/share/hadoop/contrib/hod/support
/usr/share/hadoop/contrib/hod/support/checklimits.sh
/usr/share/hadoop/contrib/hod/support/logcondense.py
/usr/share/hadoop/contrib/hod/support/logcondense.pyc
/usr/share/hadoop/contrib/hod/support/logcondense.pyo
/usr/share/hadoop/contrib/hod/testing
/usr/share/hadoop/contrib/hod/testing/__init__.py
/usr/share/hadoop/contrib/hod/testing/__init__.pyc
/usr/share/hadoop/contrib/hod/testing/__init__.pyo
/usr/share/hadoop/contrib/hod/testing/helper.py
/usr/share/hadoop/contrib/hod/testing/helper.pyc
/usr/share/hadoop/contrib/hod/testing/helper.pyo
/usr/share/hadoop/contrib/hod/testing/lib.py
/usr/share/hadoop/contrib/hod/testing/main.py
/usr/share/hadoop/contrib/hod/testing/main.pyc
/usr/share/hadoop/contrib/hod/testing/main.pyo
/usr/share/hadoop/contrib/hod/testing/testHadoop.py
/usr/share/hadoop/contrib/hod/testing/testHadoop.pyc
/usr/share/hadoop/contrib/hod/testing/testHadoop.pyo
/usr/share/hadoop/contrib/hod/testing/testHod.py
/usr/share/hadoop/contrib/hod/testing/testHod.pyc
/usr/share/hadoop/contrib/hod/testing/testHod.pyo
/usr/share/hadoop/contrib/hod/testing/testHodCleanup.py
/usr/share/hadoop/contrib/hod/testing/testHodCleanup.pyc
/usr/share/hadoop/contrib/hod/testing/testHodCleanup.pyo
/usr/share/hadoop/contrib/hod/testing/testHodRing.py
/usr/share/hadoop/contrib/hod/testing/testHodRing.pyc
/usr/share/hadoop/contrib/hod/testing/testHodRing.pyo
/usr/share/hadoop/contrib/hod/testing/testModule.py
/usr/share/hadoop/contrib/hod/testing/testModule.pyc
/usr/share/hadoop/contrib/hod/testing/testModule.pyo
/usr/share/hadoop/contrib/hod/testing/testRingmasterRPCs.py
/usr/share/hadoop/contrib/hod/testing/testRingmasterRPCs.pyc
/usr/share/hadoop/contrib/hod/testing/testRingmasterRPCs.pyo
/usr/share/hadoop/contrib/hod/testing/testThreads.py
/usr/share/hadoop/contrib/hod/testing/testThreads.pyc
/usr/share/hadoop/contrib/hod/testing/testThreads.pyo
/usr/share/hadoop/contrib/hod/testing/testTypes.py
/usr/share/hadoop/contrib/hod/testing/testTypes.pyc
/usr/share/hadoop/contrib/hod/testing/testTypes.pyo
/usr/share/hadoop/contrib/hod/testing/testUtil.py
/usr/share/hadoop/contrib/hod/testing/testUtil.pyc
/usr/share/hadoop/contrib/hod/testing/testUtil.pyo
/usr/share/hadoop/contrib/hod/testing/testXmlrpc.py
/usr/share/hadoop/contrib/hod/testing/testXmlrpc.pyc
/usr/share/hadoop/contrib/hod/testing/testXmlrpc.pyo
/usr/share/hadoop/contrib/index
/usr/share/hadoop/contrib/index/hadoop-index-1.1.2.jar
/usr/share/hadoop/contrib/streaming
/usr/share/hadoop/contrib/streaming/hadoop-streaming-1.1.2.jar
/usr/share/hadoop/contrib/vaidya
/usr/share/hadoop/contrib/vaidya/bin
/usr/share/hadoop/contrib/vaidya/bin/vaidya.sh
/usr/share/hadoop/contrib/vaidya/conf
/usr/share/hadoop/contrib/vaidya/conf/postex_diagnosis_tests.xml
/usr/share/hadoop/contrib/vaidya/hadoop-vaidya-1.1.2.jar
/usr/share/hadoop/hadoop-ant-1.1.2.jar
/usr/share/hadoop/hadoop-client-1.1.2.jar
/usr/share/hadoop/hadoop-core-1.1.2.jar
/usr/share/hadoop/hadoop-examples-1.1.2.jar
/usr/share/hadoop/hadoop-minicluster-1.1.2.jar
/usr/share/hadoop/hadoop-test-1.1.2.jar
/usr/share/hadoop/hadoop-tools-1.1.2.jar
/usr/share/hadoop/lib
/usr/share/hadoop/lib/asm-3.2.jar
/usr/share/hadoop/lib/aspectjrt-1.6.11.jar
/usr/share/hadoop/lib/aspectjtools-1.6.11.jar
/usr/share/hadoop/lib/commons-beanutils-1.7.0.jar
/usr/share/hadoop/lib/commons-beanutils-core-1.8.0.jar
/usr/share/hadoop/lib/commons-cli-1.2.jar
/usr/share/hadoop/lib/commons-codec-1.4.jar
/usr/share/hadoop/lib/commons-collections-3.2.1.jar
/usr/share/hadoop/lib/commons-configuration-1.6.jar
/usr/share/hadoop/lib/commons-daemon-1.0.1.jar
/usr/share/hadoop/lib/commons-digester-1.8.jar
/usr/share/hadoop/lib/commons-el-1.0.jar
/usr/share/hadoop/lib/commons-httpclient-3.0.1.jar
/usr/share/hadoop/lib/commons-io-2.1.jar
/usr/share/hadoop/lib/commons-lang-2.4.jar
/usr/share/hadoop/lib/commons-logging-1.1.1.jar
/usr/share/hadoop/lib/commons-logging-api-1.0.4.jar
/usr/share/hadoop/lib/commons-math-2.1.jar
/usr/share/hadoop/lib/commons-net-3.1.jar
/usr/share/hadoop/lib/core-3.1.1.jar
/usr/share/hadoop/lib/hadoop-capacity-scheduler-1.1.2.jar
/usr/share/hadoop/lib/hadoop-fairscheduler-1.1.2.jar
/usr/share/hadoop/lib/hadoop-thriftfs-1.1.2.jar
/usr/share/hadoop/lib/hsqldb-1.8.0.10.LICENSE.txt
/usr/share/hadoop/lib/hsqldb-1.8.0.10.jar
/usr/share/hadoop/lib/jackson-core-asl-1.8.8.jar
/usr/share/hadoop/lib/jackson-mapper-asl-1.8.8.jar
/usr/share/hadoop/lib/jasper-compiler-5.5.12.jar
/usr/share/hadoop/lib/jasper-runtime-5.5.12.jar
/usr/share/hadoop/lib/jdeb-0.8.jar
/usr/share/hadoop/lib/jdiff
/usr/share/hadoop/lib/jdiff/hadoop_0.17.0.xml
/usr/share/hadoop/lib/jdiff/hadoop_0.18.1.xml
/usr/share/hadoop/lib/jdiff/hadoop_0.18.2.xml
/usr/share/hadoop/lib/jdiff/hadoop_0.18.3.xml
/usr/share/hadoop/lib/jdiff/hadoop_0.19.0.xml
/usr/share/hadoop/lib/jdiff/hadoop_0.19.1.xml
/usr/share/hadoop/lib/jdiff/hadoop_0.19.2.xml
/usr/share/hadoop/lib/jdiff/hadoop_0.20.1.xml
/usr/share/hadoop/lib/jdiff/hadoop_0.20.205.0.xml
/usr/share/hadoop/lib/jdiff/hadoop_1.0.0.xml
/usr/share/hadoop/lib/jdiff/hadoop_1.0.1.xml
/usr/share/hadoop/lib/jdiff/hadoop_1.0.2.xml
/usr/share/hadoop/lib/jdiff/hadoop_1.0.3.xml
/usr/share/hadoop/lib/jdiff/hadoop_1.0.4.xml
/usr/share/hadoop/lib/jdiff/hadoop_1.1.0.xml
/usr/share/hadoop/lib/jdiff/hadoop_1.1.1.xml
/usr/share/hadoop/lib/jdiff/hadoop_1.1.2.xml
/usr/share/hadoop/lib/jersey-core-1.8.jar
/usr/share/hadoop/lib/jersey-json-1.8.jar
/usr/share/hadoop/lib/jersey-server-1.8.jar
/usr/share/hadoop/lib/jets3t-0.6.1.jar
/usr/share/hadoop/lib/jetty-6.1.26.jar
/usr/share/hadoop/lib/jetty-util-6.1.26.jar
/usr/share/hadoop/lib/jsch-0.1.42.jar
/usr/share/hadoop/lib/jsp-2.1
/usr/share/hadoop/lib/jsp-2.1/jsp-2.1.jar
/usr/share/hadoop/lib/jsp-2.1/jsp-api-2.1.jar
/usr/share/hadoop/lib/junit-4.5.jar
/usr/share/hadoop/lib/kfs-0.2.2.jar
/usr/share/hadoop/lib/kfs-0.2.LICENSE.txt
/usr/share/hadoop/lib/log4j-1.2.15.jar
/usr/share/hadoop/lib/mockito-all-1.8.5.jar
/usr/share/hadoop/lib/oro-2.0.8.jar
/usr/share/hadoop/lib/servlet-api-2.5-20081211.jar
/usr/share/hadoop/lib/slf4j-api-1.4.3.jar
/usr/share/hadoop/lib/slf4j-log4j12-1.4.3.jar
/usr/share/hadoop/lib/xmlenc-0.52.jar
/usr/share/hadoop/templates
/usr/share/hadoop/templates/conf
/usr/share/hadoop/templates/conf/capacity-scheduler.xml
/usr/share/hadoop/templates/conf/commons-logging.properties
/usr/share/hadoop/templates/conf/core-site.xml
/usr/share/hadoop/templates/conf/hadoop-env.sh
/usr/share/hadoop/templates/conf/hadoop-metrics2.properties
/usr/share/hadoop/templates/conf/hadoop-policy.xml
/usr/share/hadoop/templates/conf/hdfs-site.xml
/usr/share/hadoop/templates/conf/log4j.properties
/usr/share/hadoop/templates/conf/mapred-queue-acls.xml
/usr/share/hadoop/templates/conf/mapred-site.xml
/usr/share/hadoop/templates/conf/taskcontroller.cfg
/usr/share/hadoop/webapps
/usr/share/hadoop/webapps/datanode
/usr/share/hadoop/webapps/datanode/WEB-INF
/usr/share/hadoop/webapps/datanode/WEB-INF/web.xml
/usr/share/hadoop/webapps/hdfs
/usr/share/hadoop/webapps/hdfs/WEB-INF
/usr/share/hadoop/webapps/hdfs/WEB-INF/web.xml
/usr/share/hadoop/webapps/hdfs/index.html
/usr/share/hadoop/webapps/history
/usr/share/hadoop/webapps/history/WEB-INF
/usr/share/hadoop/webapps/history/WEB-INF/web.xml
/usr/share/hadoop/webapps/job
/usr/share/hadoop/webapps/job/WEB-INF
/usr/share/hadoop/webapps/job/WEB-INF/web.xml
/usr/share/hadoop/webapps/job/analysejobhistory.jsp
/usr/share/hadoop/webapps/job/gethistory.jsp
/usr/share/hadoop/webapps/job/index.html
/usr/share/hadoop/webapps/job/job_authorization_error.jsp
/usr/share/hadoop/webapps/job/jobblacklistedtrackers.jsp
/usr/share/hadoop/webapps/job/jobconf.jsp
/usr/share/hadoop/webapps/job/jobconf_history.jsp
/usr/share/hadoop/webapps/job/jobdetails.jsp
/usr/share/hadoop/webapps/job/jobdetailshistory.jsp
/usr/share/hadoop/webapps/job/jobfailures.jsp
/usr/share/hadoop/webapps/job/jobhistory.jsp
/usr/share/hadoop/webapps/job/jobhistoryhome.jsp
/usr/share/hadoop/webapps/job/jobqueue_details.jsp
/usr/share/hadoop/webapps/job/jobtasks.jsp
/usr/share/hadoop/webapps/job/jobtaskshistory.jsp
/usr/share/hadoop/webapps/job/jobtracker.jsp
/usr/share/hadoop/webapps/job/legacyjobhistory.jsp
/usr/share/hadoop/webapps/job/loadhistory.jsp
/usr/share/hadoop/webapps/job/machines.jsp
/usr/share/hadoop/webapps/job/taskdetails.jsp
/usr/share/hadoop/webapps/job/taskdetailshistory.jsp
/usr/share/hadoop/webapps/job/taskstats.jsp
/usr/share/hadoop/webapps/job/taskstatshistory.jsp
/usr/share/hadoop/webapps/secondary
/usr/share/hadoop/webapps/secondary/WEB-INF
/usr/share/hadoop/webapps/static
/usr/share/hadoop/webapps/static/hadoop-logo.jpg
/usr/share/hadoop/webapps/static/hadoop.css
/usr/share/hadoop/webapps/static/jobconf.xsl
/usr/share/hadoop/webapps/static/jobtracker.js
/usr/share/hadoop/webapps/static/sorttable.js
/usr/share/hadoop/webapps/task
/usr/share/hadoop/webapps/task/WEB-INF
/usr/share/hadoop/webapps/task/WEB-INF/web.xml
/usr/share/hadoop/webapps/task/index.html
/var/log/hadoop
/var/run/hadoop
			</pre></div></div></div><div xmlns="" id="disqus_thread"></div><script xmlns="" type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */

            if(document.domain == 'netkiller.github.com'){
            var disqus_shortname = 'netkiller'; // required: replace example with your forum shortname
            }else{
			var disqus_shortname = 'neochan';
            }

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script><noscript xmlns="">Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a xmlns="" href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="moosefs.html">上一页</a> </td><td width="20%" align="center"><a accesskey="u" href="distributed-filesystem.html">上一级</a></td><td width="40%" align="right"> <a accesskey="n" href="ceph.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">4. Moose File System </td><td width="20%" align="center"><a accesskey="h" href="../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 6. Ceph</td></tr></table></div><script xmlns="" type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-11694057-1']);
  _gaq.push(['_setDomainName', 'netkiller.github.io']);
  _gaq.push(['_setAllowLinker', true]);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script><script xmlns="" type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F997cd4a7320a82d72cb74d179118f697' type='text/javascript'%3E%3C/script%3E"));
</script></body></html>