<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>第 20 章 Apache Hive</title><link rel="stylesheet" type="text/css" href="..//docbook.css" /><meta name="generator" content="DocBook XSL Stylesheets V1.79.1" /><meta name="keywords" content="MySQL, PostgreSQL, Oracle, NoSQL, ER, TokyoCabinet/Tyrant, Memcache, Membase, Redis, Flare, Voldemort, LevelDB, MongoDB, GreenSQL, RDBMS, ORDBMS" /><link rel="home" href="../index.html" title="Netkiller Database 手札" /><link rel="up" href="../index.html" title="Netkiller Database 手札" /><link rel="prev" href="../apache-hbase/hbase.faq.html" title="19.5. FAQ" /><link rel="next" href="beeline.html" title="20.2. beeline" /></head><body><a xmlns="" href="//www.netkiller.cn/">Home</a> |
		<a xmlns="" href="//netkiller.github.io/">简体中文</a> |
	    <a xmlns="" href="http://netkiller.sourceforge.net/">繁体中文</a> |
	    <a xmlns="" href="/journal/index.html">杂文</a> |
	    <a xmlns="" href="//www.netkiller.cn/home/donations.html">打赏(Donations)</a> |
	    <a xmlns="" href="http://netkiller-github-com.iteye.com/">ITEYE 博客</a> |
	    <a xmlns="" href="http://my.oschina.net/neochen/">OSChina 博客</a> |
	    <a xmlns="" href="https://www.facebook.com/bg7nyt">Facebook</a> |
	    <a xmlns="" href="http://cn.linkedin.com/in/netkiller/">Linkedin</a> |
	    <a xmlns="" href="https://zhuanlan.zhihu.com/netkiller">知乎专栏</a> |
	    <a xmlns="" href="/search.html">Search</a> |
		<a xmlns="" href="mailto:netkiller@msn.com">Email</a><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">第 20 章 Apache Hive</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="../apache-hbase/hbase.faq.html">上一页</a> </td><th width="60%" align="center"> </th><td width="20%" align="right"> <a accesskey="n" href="beeline.html">下一页</a></td></tr></table><hr /></div><table xmlns=""><tr><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=watch&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;repo=netkiller.github.io&amp;type=fork&amp;count=true&amp;size=large" height="30" width="170" frameborder="0" scrolling="0" style="width:170px; height: 30px;" allowTransparency="true"></iframe></td><td><iframe src="//ghbtns.com/github-btn.html?user=netkiller&amp;type=follow&amp;count=true&amp;size=large" height="30" width="240" frameborder="0" scrolling="0" style="width:240px; height: 30px;" allowTransparency="true"></iframe></td></tr></table><div class="chapter"><div class="titlepage"><div><div><h1 class="title"><a id="index"></a>第 20 章 Apache Hive</h1></div></div></div><div class="toc"><p><strong>目录</strong></p><dl class="toc"><dt><span class="section"><a href="index.html#setup">20.1. 安装 Apache Hive</a></span></dt><dd><dl><dt><span class="section"><a href="index.html#idp52">20.1.1. MySQL</a></span></dt><dt><span class="section"><a href="index.html#idp53">20.1.2. Hadoop</a></span></dt><dt><span class="section"><a href="index.html#idp54">20.1.3. Hive</a></span></dt><dt><span class="section"><a href="index.html#idp55">20.1.4. 启动 Hive</a></span></dt><dt><span class="section"><a href="index.html#idp56">20.1.5. 访问 Hive</a></span></dt><dt><span class="section"><a href="index.html#idp57">20.1.6. 配置 hiveserver2</a></span></dt></dl></dd><dt><span class="section"><a href="beeline.html">20.2. beeline</a></span></dt><dt><span class="section"><a href="hive.shell.html">20.3. 管理 Hive</a></span></dt><dd><dl><dt><span class="section"><a href="hive.shell.html#idp65">20.3.1. 表管理</a></span></dt><dd><dl><dt><span class="section"><a href="hive.shell.html#idp58">20.3.1.1. 创建表</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp59">20.3.1.2. 显示表</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp60">20.3.1.3. 删除表</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp61">20.3.1.4. 查看表结构</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp62">20.3.1.5. 为表增加字段</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp63">20.3.1.6. 修改表名称</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp64">20.3.1.7. 使用已有表结构创建新表</a></span></dt></dl></dd><dt><span class="section"><a href="hive.shell.html#idp70">20.3.2. 分区表</a></span></dt><dd><dl><dt><span class="section"><a href="hive.shell.html#idp66">20.3.2.1. 创建分区表</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp67">20.3.2.2. 显示分区情况</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp68">20.3.2.3. 增加分区</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp69">20.3.2.4. 向分区表导入数据</a></span></dt></dl></dd><dt><span class="section"><a href="hive.shell.html#idp73">20.3.3. 视图管理</a></span></dt><dd><dl><dt><span class="section"><a href="hive.shell.html#idp71">20.3.3.1. 创建视图</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp72">20.3.3.2. 删除视图</a></span></dt></dl></dd><dt><span class="section"><a href="hive.shell.html#idp78">20.3.4. 数据管理</a></span></dt><dd><dl><dt><span class="section"><a href="hive.shell.html#idp74">20.3.4.1. 从文本文件导入数据</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp75">20.3.4.2. 从其他表查询数据并创建新表</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp76">20.3.4.3. 从其他表查询数据然后插入指定表中</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp77">20.3.4.4. </a></span></dt></dl></dd><dt><span class="section"><a href="hive.shell.html#idp82">20.3.5. HDFS与本地文件系统管理</a></span></dt><dd><dl><dt><span class="section"><a href="hive.shell.html#idp79">20.3.5.1. HDFS 目录迁移</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp80">20.3.5.2. 导出表数据到本地文件</a></span></dt><dt><span class="section"><a href="hive.shell.html#idp81">20.3.5.3. </a></span></dt></dl></dd></dl></dd><dt><span class="section"><a href="HiveQL.html">20.4. HiveQL - Hive查询语言</a></span></dt><dd><dl><dt><span class="section"><a href="HiveQL.html#idp83">20.4.1. JOIN 连接查询</a></span></dt><dt><span class="section"><a href="HiveQL.html#idp84">20.4.2. 子查询</a></span></dt></dl></dd><dt><span class="section"><a href="hive.faq.html">20.5. FAQ</a></span></dt><dd><dl><dt><span class="section"><a href="hive.faq.html#idp85">20.5.1. adoop.security.authorize.AuthorizationException): User: hadoop is not allowed to impersonate anonymous</a></span></dt></dl></dd></dl></div>
	
	<p>Hive是基于Hadoop构建的一套数据仓库分析系统，它提供了丰富的SQL查询方式来分析存储在Hadoop 分布式文件系统中的数据。其在Hadoop的架构体系中承担了一个SQL解析的过程，它提供了对外的入口来获取用户的指令然后对指令进行分析，解析出一个MapReduce程序组成可执行计划，并按照该计划生成对应的MapReduce任务提交给Hadoop集群处理，获取最终的结果。</p>
	<div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="setup"></a>20.1. 安装 Apache Hive</h2></div></div></div>
		
		<p>安装 Apache Hive 需要 Hadoop和MySQL，这里假设你已经懂得如何安装Hadoop和MySQL，所以一下将采用<a class="ulink" href="https://github.com/oscm/shell" target="_top">Netkiller OSCM</a>一件安装脚本来初始化Hadoop和MySQL,如果需要详细的安装步骤请参考笔者的相关文章。</p>

		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idp52"></a>20.1.1. MySQL</h3></div></div></div>
			
			<p>默认情况下, Hive 使用内嵌的 Derby 数据库保存元数据, 通常生产环境会使用 MySQL 来存放 Hive 元数据。</p>
			<p>使用下面脚本一键安装MySQL 5.7 安装后会显示mysql的初始密码，是所有初始密码登陆后修改为你的需要密码</p>
			<pre class="screen">
			
curl -s https://raw.githubusercontent.com/oscm/shell/master/database/mysql/5.7/mysql.server.sh | bash

2016-02-16T08:22:58.253030Z 1 [Note] A temporary password is generated for root@localhost: sd%%my.Ak7Ma
			
			</pre>
			<p>安装 MySQL JDBC 连接库。</p>
			<pre class="screen">
			
curl -s https://raw.githubusercontent.com/oscm/shell/master/database/mysql/5.7/mysql-connector-java.sh | bash
			
			</pre>
			<p>创建一个 hive 数据库用来存储 Hive 元数据，且数据库访问的用户名和密码都为 hive。</p>
			<pre class="screen">
			
mysql&gt; CREATE DATABASE hive; 
Query OK, 1 row affected (0.03 sec)
			
			</pre>
			<p>创建用户hive并授权访问hive数据库</p>
			<pre class="screen">
			
mysql&gt; CREATE USER 'hive'@'localhost' IDENTIFIED BY 'hive';
Query OK, 0 rows affected (0.04 sec)

mysql&gt; GRANT ALL ON hive.* TO 'hive'@'localhost' IDENTIFIED BY 'hive';
Query OK, 0 rows affected (0.01 sec)

mysql&gt; GRANT ALL ON hive.* TO 'hive'@'%' IDENTIFIED BY 'hive';
Query OK, 0 rows affected (0.00 sec)

mysql&gt; FLUSH PRIVILEGES;
Query OK, 0 rows affected (0.00 sec)

mysql&gt; quit;
Bye
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idp53"></a>20.1.2. Hadoop</h3></div></div></div>
			
			<p>安装 Hadoop 采用单机模式</p>
			<pre class="screen">
			
curl -s https://raw.githubusercontent.com/oscm/shell/master/distributed/hadoop/hadoop-2.8.0.sh | bash
curl -s https://raw.githubusercontent.com/oscm/shell/master/distributed/hadoop/single.sh | bash
curl -s https://raw.githubusercontent.com/oscm/shell/master/distributed/hadoop/startup.sh | bash 
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idp54"></a>20.1.3. Hive</h3></div></div></div>
			
			<p>可以从 Apache 镜像站点中下载最新稳定版的 apache-hive-2.1.1-bin.tar.gz</p>
			<pre class="screen">
			
cd /usr/local/src
wget http://mirrors.hust.edu.cn/apache/hive/stable-2/apache-hive-2.1.1-bin.tar.gz

tar zxf apache-hive-2.1.1-bin.tar.gz
mv apache-hive-2.1.1-bin /srv/apache-hive-2.1.1
ln -s /srv/apache-hive-2.1.1/ /srv/apache-hive
chown hadoop:hadoop -R /srv/apache-hive-2.1.1
			
			</pre>
			<p></p>
			<pre class="screen">
			
cat &gt; /srv/apache-hive/conf/hive-env.sh &lt;&lt;'EOF'
export JAVA_HOME=/srv/java
export HADOOP_HOME=/srv/apache-hadoop
export HBASE_HOME=/srv/apache-hbase
export HIVE_HOME=/srv/apache-hive
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin
EOF

cat &gt;&gt; ~/.bash_profile &lt;&lt;'EOF'
export JAVA_HOME=/srv/java
export HADOOP_HOME=/srv/apache-hadoop
export HBASE_HOME=/srv/apache-hbase
export HIVE_HOME=/srv/apache-hive
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HIVE_HOME/bin
EOF

source ~/.bash_profile
			
			</pre>
			<p>安装JDBC驱动</p>
			<pre class="screen">
			
[root@localhost apache-hive]# ln -s  /usr/share/java/mysql-connector-java.jar /srv/apache-hive/lib/
[root@localhost apache-hive]# ll /srv/apache-hive/lib/mysql-connector-java.jar 
lrwxrwxrwx 1 root root 40 Jun 29 01:59 /srv/apache-hive/lib/mysql-connector-java.jar -&gt; /usr/share/java/mysql-connector-java.jar
			
			</pre>
			<p>修改 hive-site.xml 配置文件，配置工作目录</p>
			<pre class="screen">
			
&lt;property&gt;
    &lt;name&gt;system:java.io.tmpdir&lt;/name&gt;
    &lt;value&gt;/tmp/hive&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;system:user.name&lt;/name&gt;
    &lt;value&gt;hadoop&lt;/value&gt;
&lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hive.querylog.location&lt;/name&gt;
    &lt;value&gt;/tmp/live/hadoop&lt;/value&gt;
    &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;
    &lt;value&gt;/tmp/hive&lt;/value&gt;
    &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;
    &lt;value&gt;/tmp/hive/${hive.session.id}_resources&lt;/value&gt;
    &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;hive.querylog.location&lt;/name&gt;
    &lt;value&gt;/user/hive/log&lt;/value&gt;
    &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;
  &lt;/property&gt;
			
			</pre>
			<p>把默认的 Derby 修改为 MySQL 需要在该文件中配置 MySQL 数据库连接信息。</p>
			<pre class="screen">
			
&lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
    &lt;value&gt;jdbc:derby:;databaseName=metastore_db;create=true&lt;/value&gt;
    &lt;description&gt;
      JDBC connect string for a JDBC metastore.
      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
    &lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
    &lt;value&gt;org.apache.derby.jdbc.EmbeddedDriver&lt;/value&gt;
    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
    &lt;value&gt;APP&lt;/value&gt;
    &lt;description&gt;Username to use against metastore database&lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
    &lt;value&gt;mine&lt;/value&gt;
    &lt;description&gt;password to use against metastore database&lt;/description&gt;
  &lt;/property&gt;
			
			</pre>
			<p>将上面配置项 value 改为下面的配置</p>
			<pre class="screen">
			
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
    &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;amp;characterEncoding=UTF-8&amp;amp;useSSL=false&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
    &lt;value&gt;hive&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
    &lt;value&gt;hive&lt;/value&gt;
  &lt;/property&gt;
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idp55"></a>20.1.4. 启动 Hive</h3></div></div></div>
			
			<p>启动 Hive 前你必须做两件事，一是创建HDFS目录，二是初始化 MySQL 数据库。</p>
			<p>为 Hive 创建 HDFS 工作目录并给它们赋相应的权限。</p>
			<pre class="screen">
			
[root@localhost ~]$ su - hadoop
[hadoop@localhost ~]$ /srv/apache-hadoop/bin/hdfs dfs -mkdir -p /user/hive/warehouse
[hadoop@localhost ~]$ /srv/apache-hadoop/bin/hdfs dfs -mkdir -p /tmp/hive
[hadoop@localhost ~]$ /srv/apache-hadoop/bin/hdfs dfs -chmod g+w /user/hive/warehouse
[hadoop@localhost ~]$ /srv/apache-hadoop/bin/hdfs dfs -chmod 777 /tmp/hive
			
			</pre>
			<p>初始化 MySQL 数据库</p>
			<pre class="screen">
			
[hadoop@localhost ~]$ /srv/apache-hive/bin/schematool -dbType mysql -initSchema
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/srv/apache-hive-2.1.1/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/srv/apache-hadoop-2.8.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Metastore connection URL:	 jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;characterEncoding=UTF-8&amp;useSSL=false
Metastore Connection Driver :	 com.mysql.jdbc.Driver
Metastore connection User:	 hive
Starting metastore schema initialization to 2.1.0
Initialization script hive-schema-2.1.0.mysql.sql
Initialization script completed
schemaTool completed
			
			</pre>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idp56"></a>20.1.5. 访问 Hive</h3></div></div></div>
			
			<p>启动 Hadoop</p>
			<pre class="screen">
			
[hadoop@localhost ~]$ /srv/apache-hadoop/sbin/start-all.sh 
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
Starting namenodes on [localhost]
localhost: starting namenode, logging to /srv/apache-hadoop-2.8.0/logs/hadoop-hadoop-namenode-localhost.localdomain.out
localhost: starting datanode, logging to /srv/apache-hadoop-2.8.0/logs/hadoop-hadoop-datanode-localhost.localdomain.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /srv/apache-hadoop-2.8.0/logs/hadoop-hadoop-secondarynamenode-localhost.localdomain.out
starting yarn daemons
starting resourcemanager, logging to /srv/apache-hadoop-2.8.0/logs/yarn-hadoop-resourcemanager-localhost.localdomain.out
localhost: starting nodemanager, logging to /srv/apache-hadoop-2.8.0/logs/yarn-hadoop-nodemanager-localhost.localdomain.out
			
			</pre>
			<p>进入 Hive 然后输入 show databases; 测试安装是否正常。</p>
			<pre class="screen">
			
[hadoop@localhost conf]$ /srv/apache-hive/bin/hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/srv/apache-hive-2.1.1/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/srv/apache-hadoop-2.8.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in file:/srv/apache-hive-2.1.1/conf/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive&gt; show databases;
OK
default
Time taken: 0.264 seconds, Fetched: 1 row(s)
hive&gt;			
			
			</pre>
			<p>至此 Apache Hive 已经安装配置完成！</p>
		</div>
		<div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="idp57"></a>20.1.6. 配置 hiveserver2</h3></div></div></div>
			
			<p>hiveserver2 提供远程访问 Hive 服务，用户可以通过IP地址和端口号连接到Hive，类似mysql client</p>
			<pre class="screen">
			
[hadoop@localhost ~]$ /srv/apache-hive/bin/hiveserver2 
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/srv/apache-hive-2.1.1/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/srv/apache-hadoop-2.8.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
			
			</pre>
			<p>检查端口</p>
			<pre class="screen">
[hadoop@localhost bin]$ ss -lnt | grep 10000
LISTEN     0      50           *:10000                    *:* 
			</pre>
			<p>测试 beeline 是否可以正常进入</p>
			<pre class="screen">
			
[hadoop@localhost ~]$ /srv/apache-hive/bin/beeline -u jdbc:hive2://
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/srv/apache-hive-2.1.1/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/srv/apache-hadoop-2.8.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://
17/06/29 22:01:16 [main]: WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
Connected to: Apache Hive (version 2.1.1)
Driver: Hive JDBC (version 2.1.1)
17/06/29 22:01:16 [main]: WARN jdbc.HiveConnection: Request to set autoCommit to false; Hive does not support autoCommit=false.
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.1.1 by Apache Hive
0: jdbc:hive2://&gt; show databases;
OK
+----------------+--+
| database_name  |
+----------------+--+
| default        |
+----------------+--+
1 row selected (1.318 seconds)
			
			</pre>
			<p>如果是生产环境启动请使用下面的方法</p>
			<pre class="screen">
			
[hadoop@localhost ~]$ /srv/apache-hive/bin/hive --service hiveserver2 &amp;
[1] 20375
[hadoop@localhost ~]$ SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/srv/apache-hive-2.1.1/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/srv/apache-hadoop-2.8.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]			
			
			</pre>
		</div>
	</div>
	
	
	
	
</div><div xmlns="" id="disqus_thread"></div><script xmlns="">

var disqus_config = function () {
this.page.url = "http://www.netkiller.cn";  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = 'netkiller'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//netkiller.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script><noscript xmlns="">Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><br xmlns="" /><script xmlns="" type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=r5HG&amp;d=9mi5r_kkDC8uxG8HuY3p4-2qgeeVypAK9vMD-2P6BYM"></script><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="../apache-hbase/hbase.faq.html">上一页</a> </td><td width="20%" align="center"> </td><td width="40%" align="right"> <a accesskey="n" href="beeline.html">下一页</a></td></tr><tr><td width="40%" align="left" valign="top">19.5. FAQ </td><td width="20%" align="center"><a accesskey="h" href="../index.html">起始页</a></td><td width="40%" align="right" valign="top"> 20.2. beeline</td></tr></table></div><script xmlns="">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-11694057-1', 'auto');
  ga('send', 'pageview');

</script><script xmlns="" async="async">
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?93967759a51cda79e49bf4e34d0b0f2c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script xmlns="" async="async">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><script xmlns="" type="text/javascript" src="/js/q.js" async="async"></script></body></html>